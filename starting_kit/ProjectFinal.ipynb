{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sklearn as sk\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import pickle\n",
    "from os.path import isfile\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "problem_dir = 'ingestion_program/'\n",
    "path.append(problem_dir);\n",
    "scoring_dir = 'scoring_program/'\n",
    "path.append(scoring_dir);\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_io import read_as_df\n",
    "data_dir = 'all_data'\n",
    "data_name = 'xporters'\n",
    "\n",
    "\n",
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = read_as_df(data_dir  + '/' + data_name)  \n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataFrame.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierDetection(data):\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "    outlier = clf.fit_predict(data)\n",
    "    countInlier = 0\n",
    "    for i in outlier:\n",
    "        if i == 1:\n",
    "            countInlier = countInlier + 1\n",
    "    realData = np.ndarray(shape=(countInlier,60))\n",
    "    count = 0\n",
    "    for i in range(len(outlier)):\n",
    "        if outlier[i] == 1:\n",
    "            realData[count] = data[i]\n",
    "            count = count + 1\n",
    "    return realData\n",
    "\n",
    "def dimensionReduction(nbDimension, data):\n",
    "    pca = PCA(n_components=nbDimension)\n",
    "    realData = np.ndarray(shape=(data.shape[0],nbDimension))\n",
    "    realData = pca.fit_transform(data)\n",
    "    return realData\n",
    "\n",
    "def getTarget(data):\n",
    "    Y = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        Y[i] = data[i,59]\n",
    "    return Y\n",
    "\n",
    "\n",
    "def featuresSelection(data, dataTarget, optionalEstimator, max_depth_tree, min_sample_leaf_tree):\n",
    "    clf = ExtraTreesClassifier(n_estimators=optionalEstimator, max_depth=max_depth_tree, min_samples_leaf=min_sample_leaf_tree) \n",
    "    clf = clf.fit(data, dataTarget)\n",
    "    model = SelectFromModel(clf, threshold=\"mean\", prefit=True)\n",
    "    realData = model.transform(data)\n",
    "    return realData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model (BaseEstimator):\n",
    "    def __init__(self, modelToUse):\n",
    "        self.num_train_samples=0\n",
    "        self.num_feat=1\n",
    "        self.num_labels=1\n",
    "        self.is_trained=False\n",
    "        self.mod = modelToUse\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.num_train_samples = X.shape[0]\n",
    "        if X.ndim>1: self.num_feat = X.shape[1]\n",
    "        print(\"FIT: dim(X)= [{:d}, {:d}]\".format(self.num_train_samples, self.num_feat))\n",
    "        num_train_samples = y.shape[0]\n",
    "        if y.ndim>1: self.num_labels = y.shape[1]\n",
    "        print(\"FIT: dim(y)= [{:d}, {:d}]\".format(num_train_samples, self.num_labels))\n",
    "        if (self.num_train_samples != num_train_samples):\n",
    "            print(\"ARRGH: number of samples in X and y do not match!\")\n",
    "        self.mod.fit(X,y)\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_test_samples = X.shape[0]\n",
    "        if X.ndim>1: num_feat = X.shape[1]\n",
    "        print(\"PREDICT: dim(X)= [{:d}, {:d}]\".format(num_test_samples, num_feat))\n",
    "        if (self.num_feat != num_feat):\n",
    "            print(\"ARRGH: number of features in X does not match training data!\")\n",
    "        print(\"PREDICT: dim(y)= [{:d}, {:d}]\".format(num_test_samples, self.num_labels))\n",
    "        y = np.zeros([num_test_samples, self.num_labels])\n",
    "        y = self.mod.predict(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot_config():\n",
    "\tsns.set()\n",
    "\tsns.set_style(\"whitegrid\")\n",
    "\tsns.set_context(\"poster\")\n",
    "\tmpl.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "\tmpl.rcParams['figure.dpi'] = 80\n",
    "\tmpl.rcParams['savefig.dpi'] = 100\n",
    "\tmpl.rcParams['font.size'] = 10\n",
    "\tmpl.rcParams['axes.labelsize'] = 10\n",
    "\tmpl.rcParams['axes.titlesize'] = 17\n",
    "\tmpl.rcParams['ytick.labelsize'] = 10\n",
    "\tmpl.rcParams['xtick.labelsize'] = 10\n",
    "\tmpl.rcParams['legend.fontsize'] = 'large'\n",
    "\tmpl.rcParams['figure.titlesize'] = 'medium'\n",
    "\n",
    "\n",
    "def plot_test_distrib(y_proba, y_test, save_path, title):\n",
    "\ttry:\n",
    "\t\tsns.distplot(proba[y_test==0, 1], label='b')\n",
    "\t\tsns.distplot(proba[y_test==1, 1], label='s')\n",
    "\t\tplt.xlabel('classifier score')\n",
    "\t\tplt.ylabel('density')\n",
    "\t\tplt.title(title)\n",
    "\t\tplt.legend()\n",
    "\t\tplt.savefig(save_path)\n",
    "\t\tplt.clf()\n",
    "\texcept Exception as e:\n",
    "\t\tprint('[WARNING] Plot test distrib failed')\n",
    "\t\tprint('[WARNING] ', str(e))\n",
    "\n",
    "\n",
    "def plot_scores(scores, scores_std, save_path, title):\n",
    "\txx = np.arange(len(scores))\n",
    "\ttry:\n",
    "\t\tplt.errorbar(xx, scores, yerr=scores_std, fmt='o',\n",
    "\t\tcapsize=20, capthick=2, label='scores')\n",
    "\t\tplt.xlabel('iter num')\n",
    "\t\tplt.ylabel('scores')\n",
    "\t\tplt.title(title)\n",
    "\t\tplt.legend()\n",
    "\t\tplt.savefig(save_path)\n",
    "\t\tplt.clf()\n",
    "\texcept Exception as e:\n",
    "\t\tprint('[WARNING] Plot scores failed')\n",
    "\t\tprint('[WARNING] ', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partie préprocessing\n",
    "\n",
    "# Ici j'ai mis que le outlierDetection mais libre à toi de check avec ou sans les autres ou sans rien pour voir le plus optimal\n",
    "\n",
    "data = outlierDetection(data)\n",
    "\n",
    "# @param nbDimension = nombre de dimensions que tu veux à la fin, data = array avec les donées\n",
    "\n",
    "# data = dimensionReduction(nbDimension, data)\n",
    "\n",
    "# @param data = array avec les donées, dataTarget = les targets des données (donné avec getTarget ;) ) \n",
    "#        optionalEstimator = nombre d'arbres dans la forêt (10 - 100), max_depth_tree = Profondeur de l'arbre (Attention ! Trop grand = problème)\n",
    "#        min_sample_leaf_tree = nombres de valeurs par feuilles (Attention ! trop petit = problème)\n",
    "\n",
    "# Target = getTarget(data)\n",
    "\n",
    "# data = featuresSelection(data, dataTarget, optionalEstimator, max_depth_tree, min_sample_leaf_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partie Model\n",
    "\n",
    "M = model(RandomForestRegressor())\n",
    "M.fit(data, getTarget(data))\n",
    "score = scoring_function(getTarget(data), M.predict(data))\n",
    "print('score = %5.4f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parite visualisation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
